{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import PlotEvalData, plot_eval\n",
    "from agent import Agent\n",
    "from config import Config\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "EMPTY_ENV = \"MiniGrid-Empty-Random-6x6-v0\"\n",
    "GO_TO_OBJ_ENV = \"MiniGrid-GoToObject-6x6-N2-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train control model for fetch\n",
    "agent = Agent(GO_TO_OBJ_ENV, \"a2c_fetch_control\", num_envs=16)\n",
    "if agent.frames_trained() == 0:\n",
    "    agent.eval(100)\n",
    "for i in range(50):\n",
    "    if agent.train(1e4*(i+1), 'a2c'):\n",
    "        agent.eval(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train base model for transfer learning\n",
    "agent = Agent(EMPTY_ENV, \"a2c_empty\", num_envs=2)\n",
    "for i in range(50):\n",
    "    agent.train(1e4*(i+1), 'a2c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TL models\n",
    "os.makedirs(os.path.dirname(\"storage/a2c_fetch_tl/status.pt\"), exist_ok=True)\n",
    "shutil.copy2(\"storage/a2c_empty/status.pt\", \"storage/a2c_fetch_tl/status.pt\")\n",
    "os.makedirs(os.path.dirname(\"storage/a2c_fetch_tl_w_rs/status.pt\"), exist_ok=True)\n",
    "shutil.copy2(\"storage/a2c_empty/status.pt\", \"storage/a2c_fetch_tl_w_rs/status.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import minigrid.core.constants as constants\n",
    "\n",
    "MAX_REWARD = 1\n",
    "COLOR_NAMES = constants.COLOR_NAMES\n",
    "OBJECT_NAMES = sorted(list(constants.OBJECT_TO_IDX.keys()))\n",
    "ACTION_NAMES = [\"get\"]\n",
    "ACTION_TO_ACTIONS = {\n",
    "    \"get\": [0,1,2]\n",
    "}\n",
    "\n",
    "def reshape_reward(obs, action, reward, done):\n",
    "    # no need to reshape if done\n",
    "    if done:\n",
    "        return reward\n",
    "    \n",
    "    # guess target tile\n",
    "    mission = obs['mission']\n",
    "    if mission is None:\n",
    "        return reward\n",
    "    for color in COLOR_NAMES:\n",
    "        if color in mission:\n",
    "            target_color = color\n",
    "            break\n",
    "    for obj in OBJECT_NAMES:\n",
    "        if obj in mission:\n",
    "            target_obj = obj\n",
    "            break\n",
    "    target = np.array([constants.OBJECT_TO_IDX[target_obj], constants.COLOR_TO_IDX[target_color], 0])\n",
    "\n",
    "    # find target tile\n",
    "    target_pos = None\n",
    "    for x,r in enumerate(obs['image']):\n",
    "        for y,c in enumerate(r):\n",
    "            if np.array_equal(c, target):\n",
    "                target_pos = np.array([x,y])\n",
    "                break\n",
    "        if target_pos is not None:\n",
    "            break\n",
    "    if target_pos is not None:\n",
    "        # give reward based on distance to target\n",
    "        man_dist = find_manhattan_distance(target_pos, np.array([3,4]))\n",
    "        if man_dist > 0:\n",
    "            reward += 1/(man_dist*50)\n",
    "    return MAX_REWARD if reward > MAX_REWARD else reward\n",
    "\n",
    "def find_manhattan_distance(p1, p2):\n",
    "    return np.sum(np.abs(p1-p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train tl only model\n",
    "agent = Agent(GO_TO_OBJ_ENV, \"a2c_fetch_tl\", num_envs=16)\n",
    "agent.eval(100)\n",
    "for i in range(50, 100):\n",
    "    if agent.train(1e4*(i+1), 'a2c'):\n",
    "        agent.eval(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train tl w rs model\n",
    "agent = Agent(GO_TO_OBJ_ENV, \"a2c_fetch_tl_w_rs\", num_envs=16)\n",
    "agent.eval(100)\n",
    "for i in range(50, 100):\n",
    "    if agent.train(1e4*(i+1), 'a2c', algo_config=Config(reshape_reward=reshape_reward)):\n",
    "        agent.eval(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval([\n",
    "    PlotEvalData(\"storage/a2c_fetch_control/eval.csv\", \"Control\", show_min_max_fill=False), \n",
    "    PlotEvalData(\"storage/a2c_fetch_tl/eval.csv\", \"TL\", color='red', frame_offset=500000, show_min_max_fill=False),\n",
    "        PlotEvalData(\"storage/a2c_fetch_tl_w_rs/eval.csv\", \"TL w/ RS\", color='pink', frame_offset=500000, show_min_max_fill=False),\n",
    "], title=\"Go To Object Using A2C\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
